apiVersion: apps/v1
kind: Deployment
metadata:
  name: llm-model-deployment
  namespace: default
  labels:
    app: llm-model
    workload: llm-model
spec:
  replicas: 2
  selector:
    matchLabels:
      app: llm-model
  template:
    metadata:
      labels:
        app: llm-model
        workload: llm-model
      annotations:
        cluster-autoscaler.kubernetes.io/safe-to-evict: "false"
    spec:
      # Node selection for ARM64 LLM nodes
      nodeSelector:
        workload: llm-model
        kubernetes.io/arch: arm64
      # Tolerations for LLM workload taint
      tolerations:
      - key: workload
        value: llm-model
        effect: NoSchedule
      # Anti-affinity to spread across nodes
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - llm-model
              topologyKey: kubernetes.io/hostname
      containers:
      - name: llm-model
        # Replace with your ARM64 LLM image
        image: huggingface/transformers-pytorch-gpu:latest
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 8000
          name: http
          protocol: TCP
        env:
        - name: MODEL_NAME
          value: "microsoft/DialoGPT-medium"
        - name: DEVICE
          value: "cpu"  # Change to "cuda" if using GPU instances
        - name: PORT
          value: "8000"
        resources:
          requests:
            cpu: "500m"
            memory: "2Gi"
          limits:
            cpu: "1000m"
            memory: "4Gi"
        livenessProbe:
          httpGet:
            path: /health
            port: http
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /ready
            port: http
          initialDelaySeconds: 5
          periodSeconds: 5
          timeoutSeconds: 3
          failureThreshold: 3
        # Graceful shutdown
        lifecycle:
          preStop:
            exec:
              command: ["/bin/sh", "-c", "sleep 15"]
        # Security context
        securityContext:
          allowPrivilegeEscalation: false
          runAsNonRoot: true
          runAsUser: 1000
          capabilities:
            drop:
            - ALL
        # Volume mounts if needed
        volumeMounts:
        - name: tmp
          mountPath: /tmp
        - name: cache
          mountPath: /cache
      volumes:
      - name: tmp
        emptyDir: {}
      - name: cache
        emptyDir: {}
      # Pod security
      securityContext:
        fsGroup: 1000
      # Restart policy
      restartPolicy: Always
      # Termination grace period
      terminationGracePeriodSeconds: 30

